%File: formatting-instruction.tex
\documentclass[letterpaper]{article}

\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{forest}

\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}
\pdfinfo{
/Heuristics and A* implementations)
/Author (Claudio Scheer)}
\setcounter{secnumdepth}{0}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}

\lstdefinestyle{pythonstyle}{
  language=Python,
  commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\ttfamily\small,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  keepspaces=true,
  numbers=left,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false
}

\begin{document}

\title{Heuristics and A* implementations}
\author{Claudio Scheer\\
  claudio.scheer@edu.pucrs.br\\
  Master's Degree in Computer Science\\
  Pontifical Catholic University of Rio Grande do Sul - PUCRS\\
  Porto Alegre - RS, Brazil\\
}
\maketitle
\begin{abstract}
  \begin{quote}
    AAAI creates proceedings, working notes, and technical reports directly from electronic source furnished by the authors. To ensure that all papers in the publication have a uniform appearance, authors must adhere to the following instructions.
  \end{quote}
\end{abstract}


\noindent Six domains were tested in the implementations: Blocksworld, Dinner, Dompteur, DWR - Dock Worker Robots, Logistics and TSP - Travel Sales Person. Not all domains were tested on the solver. However, most of the domains were tested on the heuristic functions.

In Heuristics section, I discuss the heuristics implemented. In Plan Validation section, I discuss how a plan is validated. Finally, in the section Solver using A* and $h_{max}$, I discuss the implementation of the solver. Some performance results are discussed in the Performance section.

\section{Heuristics}
In this section, I discuss the different heuristics implemented in the Jupyter notebook. The implementation uses the \textit{pddl} package to parse the tested PDDL domains and problems.

\subsection{$h_{max}$ heuristic}
In a nutshell, this heuristic returns the maximum cost to achieve a goal. From an initial state, the heuristic returns the longest path to reach all goals.

\lstinputlisting[caption={$h_{max}$ implementation}, style=pythonstyle, label=lst:h_max_python, escapechar=|]{code/h_max.txt}

In the Listing~\ref{lst:h_max_python}, the function \textit{h} returns the maximum cost to reach the \textit{goals} from an initial \textit{state}, considering a set of possible \textit{actions}.

The first reachable states are the initial states, as shown in line~\ref{line:reachable:h_max_python}. The next two lines define the goals\footnote{The goals received as a parameter are divided into positive and negative. Negative goals are those with the negative sign (\textit{not}) in the PDDL. In all heuristics, I consider only the positive goals.} and the maximum cost to achieve the goals from the reachable state. Therefore, if all goals are in the initial state, the maximum cost is $0$ and the return in line~\ref{line:while:h_max_python} is \textit{False}.

When the goals are not in the reachable state, the algorithm takes two step:

\begin{itemize}
  \item line~\ref{line:actions_applicable:h_max_python}: get all actions in which the preconditions are applicable to the current set of reachable actions.
  \item line~\ref{line:new_reachable:h_max_python}: get the effects from the actions applicable to the current reachable state. Each time the algorithm performs this step, the reachable state becomes larger, that is, it is more likely that the goals are in the reachable state.
\end{itemize}

Finally, in line~\ref{line:test_unreachable:h_max_python}, it is tested whether the new reachable states are the same as the current reachable state. If \textit{True}, there are no more states to reach and the heuristic has not achieved the goals. Therefore, $\inf$ is returned. When there are more states to test, the maximum cost is increased until all goals are reached.

\subsection{$h_{add}$ heuristic}

In a nutshell, this heuristic returns the sum of all the costs to reach the goals. The Listing~\ref{lst:h_add_python} shows the algorithm that performs this heuristic.

\lstinputlisting[caption={$h_{add}$ implementation}, style=pythonstyle, label=lst:h_add_python, escapechar=|]{code/h_add.txt}

Similar to the $h_{max}$ heuristic, the first reachable state will be the initial state and the cost of reaching goals that are in the initial state, is $0$ (line~\ref{line:initial_costs:h_add_python}). As we need to sum the cost of reaching all goals, it is necessary to maintain a set of all goals that have not yet been achieved.

When a goal is reached in the current reachable state (line~\ref{line:get_goal_reached:h_add_python}), the cost of all goals reached is added to the variable \textit{add}, as shown in line~\ref{line:reached_goal:h_add_python}.

After reaching all the goals, the variable \textit{add} is returned (line~\ref{line:return_add:h_add_python}). If some goal cannot be reached, at some point in the execution, the previous state will be equal to the reachable state, and then return $\inf$ (line~\ref{line:return_inf:h_add_python}).

To get the next reachable state I need to filter only the actions applicable to the current state and obtain the effects of those actions (line~\ref{line:new_reachable:h_add_python}). After that, the cost of each effect is calculated and added to the variable \textit{costs} (line~\ref{line:add_effect_cost:h_add_python}). The cost of the effect will be the sum of the costs of the preconditions plus 1, because it is the next step in the search tree.

\subsection{$h_{ff}$ heuristic}

The Fast Forward heuristic creates a relaxed plan for the problem, considering only the positives preconditions and positives effects. The cost of the heuristic will be the number of actions included in the plan. The Listing~\ref{lst:h_ff_python} shows the Python script to perform this heuristic.

\lstinputlisting[caption={$h_{ff}$ implementation}, style=pythonstyle, label=lst:h_ff_python, escapechar=|]{code/h_ff.txt}

The function \textit{build\_bs\_table}, line~\ref{line:build_bs_table:h_ff_python}, creates the best support table used to get the action closest to a specific action. This same function returns zero when the goals are in the initial state and $\inf$ when the goals are unreachable.

If the goals are reachable, the algorithm get the actions that best support the goals and creates a list structure (line~\ref{line:actions_to_explore:h_ff_python}). I also track all actions that have beed already explored, avoiding repeating actions.

In line~\ref{line:pop:h_ff_python}, I pop an action that was in the list and append to the list the best supported action of its preconditions. In some cases, the action does not have the best supported action. This is represented by an action named "nop". Therefore, these actions are ignored (line~\ref{line:nop:h_ff_python}). If the action has not yet been added to the plan, it will be added to the plan (line~\ref{line:plan_add:h_ff_python}) and the algorithm will continue searching (line~\ref{line:loop:h_ff_python}) for the best supported actions until all actions are processed.

In the end, line~\ref{line:return:h_ff_python}, the algorithm simply returns the plan length.

\section{Plan Validation}

In some scenarios, it is necessary to validade whether a given plan is valid or not. Listing~\ref{lst:plan_validation} shows a Python code for performing plan validation.

\lstinputlisting[caption={Plan validation implementation}, style=pythonstyle, label=lst:plan_validation, escapechar=|]{code/plan_validation.txt}

The function \textit{validate} takes as parameters the actions that can be applied to the state, the initial state, the goals and the plan to be validated. An example of a plan to be validated is shown in Listing~\ref{lst:plan_example}.

\begin{lstlisting}[label=lst:plan_example, caption={Example of a plan}, captionpos=b]
  (take k1 cc cb p1 l1)
  (load k1 r1 cc l1)
  (move r1 l1 l2)
  ...
\end{lstlisting}

The main idea of a plan validation is to apply each line of the plan to the state and test whether the goals have been reached or not. In lines~\ref{line:loop_plan:plan_validation}~and~\ref{line:loop_actions:plan_validation} of Listing~\ref{lst:plan_validation}, I search for the action that is applicable to the current line of the plan. When the plan line and an action have the same parameters (line~\ref{line:parameters:plan_validation}), I apply the action on the state, interrupt the search for another action and move to the next plan line.

After all the effects of the plan are applied to the state, I search in the state for the goals. If all goals can be found in the state, the plan is valid.


\section{Solver using A* and $h_{max}$}

A solver is responsible for finding the best path to achieve the goal. We can consider the best path as the path that performs the least actions to achieve all goals. However, the path found can be a local minimum result, that is, there is a better path but the solver cannot see it. The solver would need to keep searching to find that path. This algorithm just searches for a path that reaches all goals, not necessarily the global minimum path.

Hence, in this section, I will show how the A* differs from the Dijkstra algorithm and also an algorithm to search for the shortest path using A* search, guided by the $h_{max}$ heuristic.

\subsection{Dijkstra and A*}

A* is based on the Dijkstra algorithm. In a nutshell, Dijkstra's algorithm searches for the node in the tree that has the lowest cost. The Figure~\ref{fig:dijkstra-tree} helps to understand the Dijkstra's algorithm. Our goal is to be in city E, starting from city A.

\begin{figure}
  \centering
  \begin{forest}
    [A (0)
      [B (40)
          [E (15)]
        ]
        [C (30)
          [D (10)
              [E (15)]
            ]
        ]
    ]
  \end{forest}
  \caption{Dijkstra search tree}\label{fig:dijkstra-tree}
\end{figure}

The distance between cities A and B is 40 kilometers. Therefore, Dijkstra's algorithm will choose the path from city A to C, since the distance is shorter. In the next step, the algorithm have two possible nodes to expand: A or D. The cost to travel to each of these cities will be the current cost, 30 kilometers, plus the cost to reach A or D. Therefore, the cost to reach cities A or D is 60 and 40, respectively. Now the algorithm has three options: 1) go back and, instead of city C, choose city B, which costs 40; 2) go to city A, which costs 60; 3) go to city D, which costs 40. The algorithm will choose the cheapest path. In this case, let's assume that it arbitrarily chooses B. Following the same logic, the algorithm will have to expand all the nodes until reaching the goal.

To solve this problem, the A* algorithm adds a heuristic value to the cost of moving from a city to another, for example. The heuristic may be the straight line distance between two cities. Now the algorithm can know, for example, that the path from city A to C is longer to reach the goal than from city A to B. A bad heuristic will guide the A* algorithm to the wrong direction. However, with good heuristics, A* algorithm needs to expand fewer nodes to reach the goal.

\subsection{Solver Explanation}

The solver uses the A* algorithm, guided by the $h_{max}$ heuristic. To implement the search, I used the \textit{queue} and the \textit{pddl} packages. The first was used for the priority queue\footnote{PriorityQueue, provided by Python, always returns the value with lowest priority first. If the priority is the same, it will return, in my tests, the element added first to the queue.} and the second for parsing the PDDL domain file and problem file.

I need to store five pieces of information during the search process:

\begin{itemize}
  \item \textbf{state}: the state of the problem at a specific point. When an action is applied to the state, it creates a new state that is added to PriorityQueue;
  \item \textbf{priority}: the priority of obtaining a specific state in the next exploration. The priority is the result of the cost of the state plus the heuristic value;
  \item \textbf{cost of the state}: the cost to reach a specific state in the tree. This value is the same as the depth of the state in the tree. The cost of a new state is the cost of the previous state plus 1;
  \item \textbf{parent state}: the state that generate a new state. This information is used to search backward the actions taken to achieve the goals;
  \item \textbf{actions applied}: this is the actions applied to generate a specific state.
\end{itemize}

The next step in the algorithm is to explore the state with lowest priority. The actions whose preconditions are applicable to the current state are applied to the state and this information is stored in PriorityQueue for the next exploration. States whose heuristic value is $\inf$ are ignored.

After all goals are reached, the algorithm searches backward in the tree and returns the actions that need to be applied to reach the goals.


\section{Performance}

The heuristic used in the solver can influence in the execution time. I tested the solver using the $h_{max}$ and $h_{ff}$ heuristics. The execution time is much higher when using $h_{max}$. For example, when solving the problem 7 of the \textit{blocksworld} domain, the time using $h_{max}$ was 36.36 seconds. When using $h_{ff}$, the time was 0.07 seconds.

When testing the same problem in Web Planner, the time was 1.66 seconds. When comparing the actions required to solve a problem, the two planners show the same actions as results.


\section{Conclusions}

Some problems of the solver was discussed previously. However, just to emphesize, the A* implementation in my solver can be considered as a \textit{vanilla} implementation. The main problem I had to implement the heuristics was to translate the mathematical formulas into the Python scripts.

When analysing the performance of the heuristics implemented, the $h_{ff}$ heuristic has the best time performance. In addition, $h_{max}$ becomes worse in time consuming, as the problem increases.


\end{document}